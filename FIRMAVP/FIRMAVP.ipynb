{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import rpy2\n",
    "from rpy2 import *\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "#from rpy2.robjects import globalenv\n",
    "from rpy2.robjects.numpy2ri import numpy2ri\n",
    "from rpy2.robjects.packages import STAP\n",
    "#numpy2ri.activate()\n",
    "from rpy2.robjects import pandas2ri\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import math\n",
    "import re\n",
    "import fileinput\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "#import tkFont\n",
    "#from PIL import Image\n",
    "#from PIL import ImageTk\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di \n",
    "\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "di.display_html('''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>''', raw=True)\n",
    "\n",
    "\n",
    "#generating 621D features\n",
    "\n",
    "def feature_extraction(file_name,svalue):\n",
    "    \n",
    "    fasta_file_name=file_name + \".fasta\"\n",
    "    lines = [line.rstrip('\\n') for line in open(fasta_file_name)]    \n",
    "    save_sequences= ''\n",
    "    sequences= []\n",
    "    sequences_name= []\n",
    "    for l in lines:\n",
    "        if(l == \"\"): #blank lines are disregarded\n",
    "                pass\n",
    "        elif (l[0] == '>'):\n",
    "            sequences_name.append(l[1:])\n",
    "            sequences.append(save_sequences)\n",
    "            save_sequences= ''\n",
    "        else:\n",
    "            save_sequences+= l\n",
    "\n",
    "    sequences.append(save_sequences)\n",
    "    del sequences[0]\n",
    "    \n",
    "    \n",
    "    all_generated_features=pd.DataFrame()\n",
    "    \n",
    "\n",
    "     \n",
    "    #amino acid composition\n",
    "    \n",
    "    def aa_composition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"AAC_AVP.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        aa_comp = r.extractAAC_revised(seq)\n",
    "        return aa_comp\n",
    "    \n",
    "    #dipeptide composition\n",
    "    \n",
    "    def dc_composition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"DC_AVP.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        dc_comp = r.extractDC_revised(seq)\n",
    "        return dc_comp\n",
    "    \n",
    "    #pseudo-amino acid composition\n",
    "    \n",
    "    def pseaac_composition(seq,path):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "        r.pkgTest(\"base\")\n",
    "        r.pkgTest(\"protr\")\n",
    "    #r.source(\"SVM_prediction.R\") #calling R script to get prediction results from SVM\n",
    "    #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "    #r.pkgTest_decipher(\"DECIPHER\")\n",
    "        r.source(\"PAAC_AVP.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        pseaac_comp = r.extractPAAC_revised(seq,path)\n",
    "        return pseaac_comp\n",
    "    \n",
    "    #amphiphilic pseudo-amino acid composition\n",
    "    \n",
    "    def apseaac_composition(seq,path):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "        r.pkgTest(\"base\")\n",
    "        r.pkgTest(\"protr\")\n",
    "    #r.source(\"SVM_prediction.R\") #calling R script to get prediction results from SVM\n",
    "    #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "    #r.pkgTest_decipher(\"DECIPHER\")\n",
    "        r.source(\"APAAC_AVP.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        apseaac_comp = r.extractAPAAC_revised(seq,path)\n",
    "        return apseaac_comp\n",
    "    \n",
    "    #composition for CTD model \n",
    "    \n",
    "    def ctd_composition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"CTDC.R\") #calling R script to compute composition for CTD model\n",
    "  \n",
    "        ctd_comp = r.extractCTDC_revised(seq)\n",
    "        return ctd_comp\n",
    "    \n",
    "    \n",
    "    #transition for CTD model\n",
    "    \n",
    "    def ctd_transition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"CTDT.R\") #calling R script to compute transition for CTD model\n",
    "  \n",
    "        ctd_trans = r.extractCTDT_revised(seq)\n",
    "        return ctd_trans\n",
    "    \n",
    "    \n",
    "    #distribution for CTD model\n",
    "    \n",
    "    def ctd_distribution(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"CTDD.R\") #calling R script to compute distribution for CTD model\n",
    "  \n",
    "        ctd_distr = r.extractCTDD_revised(seq)\n",
    "        return ctd_distr\n",
    "    \n",
    "\n",
    "    \n",
    "    #generate secondary structure features\n",
    "        \n",
    "    def secondstruct_feat(seq):\n",
    "        \n",
    "        \n",
    "        base = importr('base')\n",
    "        \n",
    "        r=ro.r\n",
    "        #r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "        #r.pkgTest(\"base\")\n",
    "        \n",
    "        #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "        #r.pkgTest_decipher(\"DECIPHER\")\n",
    "        r.source(\"GL_new.R\") #calling R script to compute secondary structure features\n",
    "  \n",
    "        ss_ft = r.extractSSF(seq)\n",
    "        #print(ssfile)\n",
    "        return ss_ft\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    aa_dict='ARNDCEQGHILKMFPSTWYV'\n",
    "    \n",
    "    for i in range(1,21):\n",
    "        all_generated_features[\"aac_%s\"%i]=\"\"\n",
    "    \n",
    "    for i in range(1,401):\n",
    "        all_generated_features[\"dipep_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,26):\n",
    "        all_generated_features[\"pseudo_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,31):\n",
    "        all_generated_features[\"amphipseudo_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,25):\n",
    "        all_generated_features[\"comp_%s\"%i]=\"\"\n",
    "    \n",
    "    for i in range(1,25):\n",
    "        all_generated_features[\"tran_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,121):\n",
    "        all_generated_features[\"dist_%s\"%i]=\"\"\n",
    "    \n",
    "    for i in range(1,7):\n",
    "        all_generated_features[\"ss_%s\"%i]=\"\"\n",
    "    \n",
    "    \n",
    "    # Execute for each sequence\n",
    "    \n",
    "    seqs_length=[]\n",
    "    counter=0\n",
    "    counting_seq=0\n",
    "\n",
    "    for seq in sequences:\n",
    "        seqs_length.append(len(seq))\n",
    "        counter+=1\n",
    "        aa_comp=aa_composition(seq)\n",
    "        dir_path = os.getcwd()\n",
    "        dir_path = dir_path.replace(\"\\\\\", \"/\")\n",
    "        dir_path+=\"/AAidx.csv\"\n",
    "        dc_comp=dc_composition(seq)\n",
    "        pseaac_comp=pseaac_composition(seq,dir_path)\n",
    "        apseaac_comp=apseaac_composition(seq,dir_path)\n",
    "        ctd_comp = ctd_composition(seq)\n",
    "        ctd_trans = ctd_transition(seq)\n",
    "        ctd_distr = ctd_distribution(seq)\n",
    "        ss_struct = secondstruct_feat(seq)\n",
    "        \n",
    "        all_generated_features.at[counting_seq,\"aac_1\":\"aac_20\"]=aa_comp\n",
    "        all_generated_features.at[counting_seq,\"dipep_1\":\"dipep_400\"]=dc_comp\n",
    "        all_generated_features.at[counting_seq,\"pseudo_1\":\"pseudo_25\"]=pseaac_comp\n",
    "        all_generated_features.at[counting_seq,\"amphipseudo_1\":\"amphipseudo_30\"]=apseaac_comp\n",
    "        all_generated_features.at[counting_seq,\"comp_1\":\"comp_24\"]=ctd_comp\n",
    "        all_generated_features.at[counting_seq,\"tran_1\":\"tran_24\"]=ctd_trans\n",
    "        all_generated_features.at[counting_seq,\"dist_1\":\"dist_120\"]=ctd_distr\n",
    "        all_generated_features.at[counting_seq,\"ss_1\":\"ss_6\"]=ss_struct\n",
    "        \n",
    "        x_len=len(seq)\n",
    "        \n",
    "        #get path for current directiry\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        counting_seq+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    eliminate= []\n",
    "    \n",
    "    if svalue==0:\n",
    "        #features_selected=[\"S5\", \"D80\", \"C21\", \"S4\", \"T10\", \"D81\"]\n",
    "        features_selected=[\"aac_1\",\"aac_2\",\"aac_3\",\"aac_4\",\"aac_6\",\"aac_7\",\"aac_8\",\"aac_9\",\"aac_10\",\"aac_11\",\"aac_12\",\"aac_15\",\"aac_16\",\"aac_17\",\"aac_18\",\"aac_19\",\"aac_20\",\"dipep_32\",\"dipep_51\",\"dipep_111\",\"dipep_211\",\"dipep_220\",\"dipep_340\",\"pseudo_1\",\"pseudo_2\",\"pseudo_3\",\"pseudo_4\",\"pseudo_5\",\"pseudo_10\",\"pseudo_11\",\"pseudo_12\",\"pseudo_14\",\"pseudo_16\",\"pseudo_18\",\"pseudo_20\",\"pseudo_21\",\"pseudo_22\",\"pseudo_23\",\"pseudo_24\",\"pseudo_25\",\"amphipseudo_21\",\"amphipseudo_22\",\"amphipseudo_23\",\"amphipseudo_24\",\"amphipseudo_25\",\"amphipseudo_26\",\"amphipseudo_27\",\"amphipseudo_29\",\"amphipseudo_30\",\"comp_1\",\"comp_2\",\"comp_3\",\"comp_4\",\"comp_5\",\"comp_6\",\"comp_10\",\"comp_11\",\"comp_13\",\"comp_14\",\"comp_15\",\"comp_16\",\"comp_17\",\"comp_18\",\"comp_19\",\"comp_21\",\"comp_22\",\"comp_23\",\"comp_24\",\"tran_1\",\"tran_2\",\"tran_3\",\"tran_4\",\"tran_5\",\"tran_6\",\"tran_11\",\"tran_12\",\"tran_13\",\"tran_14\",\"tran_16\",\"tran_17\",\"tran_18\",\"tran_19\",\"tran_20\",\"tran_21\",\"tran_22\",\"tran_23\",\"tran_24\",\"dist_1\",\"dist_2\",\"dist_3\",\"dist_4\",\"dist_7\",\"dist_8\",\"dist_9\",\"dist_10\",\"dist_11\",\"dist_12\",\"dist_13\",\"dist_14\",\"dist_15\",\"dist_16\",\"dist_17\",\"dist_18\",\"dist_22\",\"dist_23\",\"dist_24\",\"dist_25\",\"dist_26\",\"dist_27\",\"dist_28\",\"dist_29\",\"dist_30\",\"dist_32\",\"dist_34\",\"dist_38\",\"dist_41\",\"dist_46\",\"dist_47\",\"dist_50\",\"dist_52\",\"dist_53\",\"dist_55\",\"dist_56\",\"dist_61\",\"dist_62\",\"dist_63\",\"dist_65\",\"dist_67\",\"dist_68\",\"dist_70\",\"dist_71\",\"dist_72\",\"dist_73\",\"dist_76\",\"dist_77\",\"dist_78\",\"dist_79\",\"dist_82\",\"dist_83\",\"dist_84\",\"dist_85\",\"dist_86\",\"dist_87\",\"dist_88\",\"dist_89\",\"dist_90\",\"dist_91\",\"dist_93\",\"dist_94\",\"dist_97\",\"dist_99\",\"dist_100\",\"dist_102\",\"dist_103\",\"dist_105\",\"dist_106\",\"dist_107\",\"dist_108\",\"dist_109\",\"dist_112\",\"dist_113\",\"dist_114\",\"dist_115\",\"dist_116\",\"dist_117\",\"dist_118\",\"dist_119\",\"dist_120\",\"ss_1\"]\n",
    "        \n",
    "    for i in range(1,21):\n",
    "        a=\"aac_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "            \n",
    "    for i in range(1,401):\n",
    "        a=\"dipep_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    for i in range(1,26):\n",
    "        a=\"pseudo_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)        \n",
    "    \n",
    "    for i in range(1,31):\n",
    "        a=\"amphipseudo_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    for i in range(1,25):\n",
    "        a=\"comp_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "            \n",
    "    for i in range(1,25):\n",
    "        a=\"tran_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    for i in range(1,121):\n",
    "        a=\"dist_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)  \n",
    "    \n",
    "            \n",
    "    for i in range(1,7):\n",
    "        a=\"ss_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    all_generated_features=all_generated_features.drop(eliminate, axis=1)\n",
    "    \n",
    "    if svalue==0:\n",
    "        #all_generated_features=all_generated_features[['S5', 'D80', 'C21', 'S4', 'T10', 'D81']]\n",
    "        all_generated_features=all_generated_features[['aac_1','aac_2','aac_3','aac_4','aac_6','aac_7','aac_8','aac_9','aac_10','aac_11','aac_12','aac_15','aac_16','aac_17','aac_18','aac_19','aac_20','dipep_32','dipep_51','dipep_111','dipep_211','dipep_220','dipep_340','pseudo_1','pseudo_2','pseudo_3','pseudo_4','pseudo_5','pseudo_10','pseudo_11','pseudo_12','pseudo_14','pseudo_16','pseudo_18','pseudo_20','pseudo_21','pseudo_22','pseudo_23','pseudo_24','pseudo_25','amphipseudo_21','amphipseudo_22','amphipseudo_23','amphipseudo_24','amphipseudo_25','amphipseudo_26','amphipseudo_27','amphipseudo_29','amphipseudo_30','comp_1','comp_2','comp_3','comp_4','comp_5','comp_6','comp_10','comp_11','comp_13','comp_14','comp_15','comp_16','comp_17','comp_18','comp_19','comp_21','comp_22','comp_23','comp_24','tran_1','tran_2','tran_3','tran_4','tran_5','tran_6','tran_11','tran_12','tran_13','tran_14','tran_16','tran_17','tran_18','tran_19','tran_20','tran_21','tran_22','tran_23','tran_24','dist_1','dist_2','dist_3','dist_4','dist_7','dist_8','dist_9','dist_10','dist_11','dist_12','dist_13','dist_14','dist_15','dist_16','dist_17','dist_18','dist_22','dist_23','dist_24','dist_25','dist_26','dist_27','dist_28','dist_29','dist_30','dist_32','dist_34','dist_38','dist_41','dist_46','dist_47','dist_50','dist_52','dist_53','dist_55','dist_56','dist_61','dist_62','dist_63','dist_65','dist_67','dist_68','dist_70','dist_71','dist_72','dist_73','dist_76','dist_77','dist_78','dist_79','dist_82','dist_83','dist_84','dist_85','dist_86','dist_87','dist_88','dist_89','dist_90','dist_91','dist_93','dist_94','dist_97','dist_99','dist_100','dist_102','dist_103','dist_105','dist_106','dist_107','dist_108','dist_109','dist_112','dist_113','dist_114','dist_115','dist_116','dist_117','dist_118','dist_119','dist_120','ss_1']]\n",
    "    \n",
    "    all_generated_features.to_csv(\"%s.csv\" %file_name, header=True, index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#predicting antiviral peptide sequences\n",
    "def predict_AVP_sequences(svalue):\n",
    "    \n",
    "    #reading training and test datsets \n",
    "    \n",
    "    dir_path = os.getcwd()\n",
    "    dir_path = dir_path.replace(\"\\\\\", \"/\")\n",
    "    if svalue==0:\n",
    "        training_file_path=dir_path + \"/selected_train_test_merged_file.csv\" #path for aac training set\n",
    "    \n",
    "    \n",
    "    testing_file_path=dir_path + \"/input_seq.csv\" #path for input sequences\n",
    "    #print(training_file_path)\n",
    "    #print(testing_file_path)\n",
    "    #base = importr('base')\n",
    "    #utils = rpackages.importr('utils')\n",
    "    #utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "    #packnames = ('ROSE', 'e1071', 'caret') \n",
    "    #utils.install_packages(StrVector(packnames))\n",
    "    r=ro.r\n",
    "    r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "    #r.pkgTest(\"ROSE\")\n",
    "    r.pkgTest(\"base\")\n",
    "    r.pkgTest(\"e1071\") #install e1071 R package if not installed\n",
    "    r.pkgTest(\"caret\")\n",
    "    #r.pkgTest(\"protr\")\n",
    "    #r.source(\"SVM_prediction.R\") #calling R script to get prediction results from SVM\n",
    "    #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "    #r.pkgTest_decipher(\"DECIPHER\")\n",
    "    r.source(\"SVM_classifier_revised_new.R\") #calling R script to get prediction results from SVM\n",
    "    predictions = r.predict_results(training_file_path,testing_file_path)\n",
    "    #print(predictions)\n",
    "    #print(predictions[1])\n",
    "    \n",
    "    \n",
    "    # #################################################################\n",
    "    lines = [line.rstrip('\\n') for line in open('input_seq.fasta')]\n",
    "    \n",
    "\n",
    "    #reading all sequences in sequences and their names in sequences_name\n",
    "    save_sequences= ''\n",
    "    sequences_input= []\n",
    "    sequences_name_input= []\n",
    "\n",
    "\n",
    "    for l in lines:\n",
    "        if(l == \"\"): #blank lines are disregarded\n",
    "                pass\n",
    "        elif (l[0] == '>'):\n",
    "            sequences_name_input.append(l[1:])\n",
    "            sequences_input.append(save_sequences)\n",
    "            save_sequences= ''\n",
    "        else:\n",
    "            save_sequences+= l\n",
    "\n",
    "    sequences_input.append(save_sequences)\n",
    "    del sequences_input[0]\n",
    "    \n",
    " \n",
    "  #generate prediction statistics\n",
    "\n",
    "    predict_file = open(\"predicted_AVP_sequences.fasta\", \"w+\")\n",
    "\n",
    "    count_resistance_sequences=0   \n",
    "    for i in range(len(predictions)):\n",
    "        if (predictions[i]==1 ):\n",
    "            predict_file.write(str(sequences_name_input[i])+ '\\n'+ '\\n')\n",
    "            count_resistance_sequences+=1\n",
    "    predict_file.close()\n",
    "    del predict_file\n",
    "\n",
    "\n",
    "    one_line=\"Total number of predicted AVP sequences = \"+str(count_resistance_sequences) + \"\\n\"  +\"\\n\" \n",
    "    with open(\"predicted_AVP_sequences.fasta\", 'r+') as fp:\n",
    "        lines = fp.readlines()     \n",
    "        lines.insert(0, one_line)  \n",
    "        fp.seek(0)                 \n",
    "        fp.writelines(lines)  \n",
    "\n",
    "\n",
    "#include new sequences to the training and test datasets \n",
    "\n",
    "def add_new_sequences(svalue,sgval): \n",
    "    file_new = open(\"input_seq.fasta\", \"r\")\n",
    "    #data_new = file_new.read()\n",
    "    file_new.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "    feature_extraction('input_seq',svalue)\n",
    "    df1 = pd.read_csv('input_seq.csv')\n",
    "    if sgval==1:\n",
    "        Otpt = [1] * df1.shape[0]\n",
    "    else:\n",
    "        Otpt = [-1] * df1.shape[0]\n",
    "    df1[\"Output\"]= Otpt\n",
    "    df1.to_csv(\"seq_excld_header.csv\", header=False, index=False)\n",
    "    file_new_features = open(\"seq_excld_header.csv\", \"r\")\n",
    "    data_new_features = file_new_features.read()\n",
    "    file_new_features.close()\n",
    "    \n",
    "    if svalue==0:\n",
    "        file_all_features= open(\"selected_train_test_merged_file.csv\",\"a\")\n",
    "    \n",
    "    \n",
    "    file_all_features.write(data_new_features)\n",
    "    file_all_features.close()\n",
    "\n",
    "    # reset training and test data sets\n",
    "def restore_training_data():\n",
    "    \n",
    "    copyfile(\"selected_train_test_merged_file_actual.csv\", \"selected_train_test_merged_file.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#build graphical user interface\n",
    "\n",
    "root = tkinter.Tk()\n",
    "root.title(\"FIRMAVP\")\n",
    "root.geometry(\"520x485\")\n",
    "root.configure(background=\"peach puff\")\n",
    "#root.wm_attributes('-alpha', 0.7)\n",
    "\n",
    "\n",
    "#canvas = Canvas(root, width=235, height = 139)  \n",
    "canvas = Canvas(root, width=159, height = 173, bg='peach puff',highlightthickness=0)\n",
    "#canvas = Canvas(root, width=362, height = 352, bg='white smoke',highlightthickness=0)\n",
    "canvas.pack(padx=1, pady=1)\n",
    "\n",
    "\n",
    "#add logo of the tool\n",
    "\n",
    "#width=389\n",
    "#height=398\n",
    "#img = Image.open(\"AS_logo_design.gif\")\n",
    "#img = PhotoImage(file=\"PARGT_logo.gif\") \n",
    "#img = img.resize((width,height), Image.ANTIALIAS)\n",
    "#photoImg =  ImageTk.PhotoImage(img)\n",
    "\n",
    "#canvas.create_image(120,71, anchor=CENTER, image=img) \n",
    "#canvas.create_image(140,145, anchor=CENTER, image=img)\n",
    "#canvas.create_image(170,130, anchor=CENTER, image=photoImg)\n",
    "\n",
    "\n",
    "T = Text(root, font=\"none 12 bold\",bd=0,height=2, width=33, padx=0, pady=0)\n",
    "\n",
    "\n",
    "\n",
    "T.pack(padx=0, pady=0)\n",
    "T.insert(END, \"         FIRM-AVP: A Tool for Antiviral\\n                   Peptide Prediction\",\"center\")\n",
    "\n",
    "\n",
    "#setup window\n",
    "\n",
    "def setup_window(soption):\n",
    "    window = Toplevel(root)\n",
    "    window.geometry(\"320x60\")\n",
    "    window.configure(background=\"tan\")\n",
    "    if soption not in choices:\n",
    "        Lbl = Label(window, bg=\"tan\",fg=\"black\",text=\"Please select an option\")\n",
    "        Lbl.config(font=('Helvetica', 8, 'bold'))\n",
    "        Lbl.pack( )\n",
    "    else:\n",
    "        Lbl = Label(window, bg=\"tan\",fg=\"black\",text=\"Operation is successful!\")\n",
    "        Lbl.config(font=('Helvetica', 8, 'bold'))\n",
    "        Lbl.pack( )\n",
    "    \n",
    "    Btn=Button(window, text=\"OK\", command=window.destroy) \n",
    "    Btn.config(font=('Helvetica', 8, 'bold'))\n",
    "    Btn.pack()\n",
    "\n",
    "    \n",
    "#peform operation based on choice    \n",
    "def submit():\n",
    "    sf = \"%s\" % var.get()\n",
    "    if var.get()==choices[0]:\n",
    "        op_value=0\n",
    "        feature_extraction('input_seq',op_value)\n",
    "        predict_AVP_sequences(op_value)\n",
    "        \n",
    "    \n",
    "    elif var.get()==choices[1]:\n",
    "        op_value=0\n",
    "        signvalue=1\n",
    "        add_new_sequences(op_value,signvalue)\n",
    "    \n",
    "    elif var.get()==choices[2]:\n",
    "        op_value=0\n",
    "        signvalue=-1\n",
    "        add_new_sequences(op_value,signvalue)\n",
    "    \n",
    "    \n",
    "    elif var.get()==choices[3]:\n",
    "        restore_training_data()\n",
    "    \n",
    "    \n",
    "    setup_window(sf)\n",
    "\n",
    "\n",
    "var = tkinter.StringVar(root)\n",
    "# initial value\n",
    "var.set('< Select option>')\n",
    "choices = ['Predict AVP sequences', \\\n",
    "           'Include new AVP sequences',  \\\n",
    "           \n",
    "           'Include new non-AVP sequences',  \\\n",
    "           \n",
    "           'Restore training sets']\n",
    "option = tkinter.OptionMenu(root, var, *choices)\n",
    "#option.config(bg = \"GREEN\")\n",
    "#helv35=font.Font(family='Helvetica', size=36)\n",
    "option.config(font=('Helvetica', 8, 'bold')) \n",
    "#option[\"menu\"].config(bg=\"GREEN\")\n",
    "option[\"menu\"].config(font=('Helvetica', 8, 'bold'))\n",
    "option.pack( padx=10, pady=40)\n",
    "button = tkinter.Button(root, text=\"Submit\", command=submit)\n",
    "button.config(font=('Helvetica', 8, 'bold'))\n",
    "button.pack(padx=10, pady=10)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
